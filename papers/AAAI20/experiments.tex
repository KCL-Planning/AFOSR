
% pgf settings: shrink the tick labels a bit
\pgfplotsset{every tick label/.append style={font=\scriptsize}}

\newcommand{\scatterplotsize}{8cm}
\newcommand{\scatterplotxlabelshift}{1.5ex}
\newcommand{\scatterplotylabelshift}{-3ex}




\section{Experiments}
\label{experiments}

%% \joerg{1.5--2 page: similar to ijcai version; expliucotly distinguish 
%% global vs local, add results for local in both ipc and action-set prop
%% experiments}

We implemented our approach in Fast Downward
(FD) \cite{helmert:jair-06}. We evaluate it, in turn, on IPC
benchmarks modified for OSP planning, and on a selection of IPC
benchmarks we extended with action-set properties.

The base planner called by our SysS and SysW algorithms on each search
node runs forward search using
\hff\ \cite{hoffmann:nebel:jair-01}, optionally with conjunction or trap learning.
%
%% The base planner configurations, used to solve/prove unsolvability
%% of a meta search node, are greedy best first search with $\hff$ and
%% preferred operators ($hff$) and conjunction learning $\hc$ with
%% $\hff$ as its base heuristic. \rebecca{ask Marcel how it is
%% called} \rebecca{Modification of hC to find deadends with an cost
%% bound}
%
The experiments were run on a cluster of Intel E5-2660 machines
running at 2.20 GHz, with time (memory) cut-offs of 30 minutes (4 GB).



 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% IPC OSP

\subsection{IPC-Based OSP Benchmarks}

% The net-benefit benchmarks don't give us anything new (the ones we
% could use are adopted from IPC ben chmarks anyhow).
%
%% \joerg{Rebecca/Michael: check out the IPC net-benefit benchmarks. Reviewers may naturally expect us to experiment with those, given our strong focus on oversubscription planning (actually this question came up in the discussion with the NASA guys yesterday). In the net-bnefit benchmarks, goal facts have rewards which we don't need. The question is whether, stripping away these rewards and imposing a plan-cost bound, we would get benchmarks not already covered by bour IPC experiments anyway. If the answer is "no", we can just say so in the paper. If the answer is "yes", it would be good (though probably not absolitely necessary) to experiment with these domains as well. In any case, we should know what the answer is.}

Following Katz et al.\ \shortcite{katz:etal:icaps-19}, for every IPC
benchmark task $(\vars,\acts,\cost,\init,\goal)$ with smallest known
plan cost $C$ as per planning.domains \cite{muise:icaps-demos-16}, we
obtained three OSP tasks by setting the cost bound to $b = x * C$
where $x \in \{0.25, 0.5, 0.75\}$. We used soft goals only, \ie,
$\goalsoft = \goal$ and $\goalhard=\emptyset$. For implementation
reasons, we omitted tasks with $\geq 32$ goals (which would be
infeasible for MUGS analysis anyhow).
%
%% ; the latter is an artifact of our current implementation that
%% could be overcome in principle, though computing all MUGS for that
%% many goals is presumably typically infeasible anyway.
%
% Joerg: said up front where it belongs
%
%% We extended conjunction learning \cite{steinmetz:hoffmann:ai-17} to
%% deal with cost bounds, thus enabling nogood learning and transfer in
%% SysS and SysW.
%
We consider conjunction learning, but not trap learning as that cannot
deal with OSP cost bounds.
%
%% In what follows, we consider first global explanations, then discuss
%% how the picture changes for local explanations.


\subsubsection{IPC Global Explanations}

\setlength{\tabcolsep}{2pt}
\renewcommand{\arraystretch}{0.8}
\begin{figure*}[h!]
\tiny
%\centering \input{tables/coverage_IPC.tex}
%
\centering \input{tables/coverage_IPC_osp.tex} 
%
\vspace{-0.2cm}
\caption{\label{table:coverage_ipc} Global explanation results on IPC benchmarks modified 
for oversubscription planning (OSP), with cost bounds set to $x$ times
optimal cost. Reference: \astar\ with \hlmcut\ on original task, and
OSP planning \cite{katz:etal:icaps-19}. SysS and SysW with vs.\
without conjunction learning \hc. Search tree fraction: fraction of
worst-case search tree explored. \#MUGS: average/maximum number of
MUGS, \ie, global explanation size. Best performance in each part
shown in \textbf{boldface}.}
\vspace{-0.5cm}
\end{figure*}

Figure~\ref{table:coverage_ipc} shows our data for global
explanations, \ie, computing all MUGS.
%
Note first the \#MUGS data in the rightmost part of the table. As the
data shows, the size of this global explanation is often small.
%
% joerg: previous text, when we didnt yet have separate analysis/data
% for local.
%
%% Observe that, if the user asks a question ``Why $r$ rather than
%% $p$?'', the answer are the properties entailed by $p$, represented
%% here through the smallest conjunctions excluded by $p$. The number of
%% such conjunctions is at most the number of MUGS. So \#MUGS corresponds
%% to worst-case answer/explanation size.
%
%% (Taking the maximum rather than average per domain, the average across
%% domains is 113.4, 45.6, 24.0 for $x=0.25, 0.5, 0.75$ respectively.)
%% \rebecca{discus new mugs max columns}
%
%% The average MUGS size for a cost bound of 0.25 is small (1.32). It
%% is often the case that for these problems, you cannot reach any of
%% the goal facts. In that case, the MUGS will be the goals.

The rest of the the figure focuses on computational performance. As a
measure to compare against, we use optimal planning and OSP as
reference points. The \hlmcut\ column gives coverage for \astar\
with \hlmcut\ \cite{helmert:domshlak:icaps-09} run on the original IPC
instance without a cost bound, as a comparison to solvable optimal
planning. The OSP column gives coverage for the most recent OSP
planner \cite{katz:etal:icaps-19}.
%
It is expected that our algorithms, solving a more complex problem,
will perform worse than the reference points. The question
is, \emph{how much worse?}

As a short summary of the answer provided by
Figure~\ref{table:coverage_ipc} to that question, compared to optimal
planning, with the smallest cost bound $x=0.25$ our analysis is
actually more effective. But that changes for larger cost bounds where
the base planner's search space is larger and accordingly our analysis
becomes harder. Taking the per-domain best of our four algorithm
configurations, for $x=0.25$ we get equal or better coverage in 37 of
the 45 domains, for $x=0.5$ that number is 25, for $x=0.75$ it is
16. Compared to OSP planning, these numbers are 29, 18, and
22. Overall, it seems fair to say that our analysis is reasonably
feasible: in many domains, it is on par with the most closely related
simpler problems.

The search tree fraction explored by SysS and SysW increases
respectively decreases with larger cost bounds, which is expected as
solvable goal subsets become larger. Yet for SysW this does not
outweigh the increased base planner effort. Conjunction learning helps
mostly for small cost bounds and/or when using SysW.
%
%% Comparing SysS and SysW, with cost bound 0.25 both show better
%% coverage in 4 domains. Among those domains, in \woodworking\
%% and \openstacks\ SysS explores a much smaller fraction of the
%% meta-search tree than SysW (0.02 vs. 0.99 and 0.06 vs. 0.99). With
%% a cost bound of 0.5 SysW has better coverage in more domains (8
%% vs. 6). With cost 0.75 both show better coverage in 7
%% domains. Although SysW explores the smaller fraction of the
%% meta-search tree, SysS still demonstrates better coverage
%% overall. \rebecca{In this setting, finding a plan is easier than
%% proving unsolvability?}
%
%% The table shows that $\hc$ is useful with SysW, but for SysS only
%% with cost bound is $0.25$.



\subsubsection{IPC Local Explanations}

For local explanations -- entailments of soft-goal conjunctions
$\bigwedge_{g \in A} g$ -- we set up an experiment where we used only
benchmark tasks with $\geq 6$ goals, scaled question size $|A|$ from
$1$ to $5$, and randomly selected $10$ questions of each
size. Figure~\ref{fig:ipc-local} shows the data for SysS and the most
challenging cost bound $0.75$.
%
As expected, both computational effort and explanation size decrease
with $|A|$.
%
Averages are taken over instances where all questions were solved, as
otherwise the results are distorted by large instances solved only for
high values of $|A|$.

\begin{figure}[ht]
\small
\centering

\begin{tabular}{cc}
\begin{minipage}{0.25\textwidth}
\resizebox{!}{3.0cm}{
\input{data/IPC_cost_bound/search_time_coverage_mix_bu.tex}
}
\end{minipage} &
\begin{minipage}{0.25\textwidth}
\resizebox{!}{3.0cm}{
\input{data/IPC_cost_bound/mugs_bu_all.tex}
}
\end{minipage}
\end{tabular}
\vspace{-0.3cm}
\caption{\label{fig:ipc-local} Local explanation results on IPC 
benchmarks for SysS as a function of $|A|$. Left: coverage, \ie,
fraction of solved questions (dashed, right y-axis); and average
runtime (solid, left y-axis). Right: average \#MUGS.\joerg{integrate
reference point coverage as horizontal lines into the left plot}\rebecca{update plot with new benchmark results}}
\vspace{-0.6cm}
\end{figure}

%\input{tables/all_points.tex}
%\input{data/IPC_cost_bound/search_time_coverage_mix_td.tex}

The results are very consistent across domains, and are much stronger
still in some cases. Of the 42 domains that have at least one instance
with $\geq 6$ goals, 7 domains have much stronger ($> 40\%$) increases
in coverage from $|A|=1$ to $|A|=5$,
%
%% For coverage, Depots, Gripper, NoMystery, Parking, Pathways,
%% Scanalyzer, Trucks
%
and in 24 domains average runtime decreases by at least one order of
magnitude. 
%
%% runtime: 1 order blocks, drive, floortile, elevators, grip, ged,
%% mic, log, mov, pipest, pipesnt, sat, psr, soko, stor, tetr, tpp,
%% transp, wood; 2 orders depots, nomystery, parcprinter, scan, trucks
%
The average number of MUGS for $|A|=5$ is less than $5$ in all
domains, including ones like Floortile, Gripper, Miconic, Woodworking
where global explanations can be large as shown in
Figure~\ref{table:coverage_ipc}.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Action-Set Properties, SUBMISSION VERSION

\subsection{Action-Set Properties}

To evaluate the use of our framework with more complex plan
properties, we experimented with the compilation of action-set
properties as per Section~\ref{actionsetprops}. 
%
We extended four domains with action-set properties: NoMystery,
Rovers, and TPP as per \cite{nakhost:etal:icaps-12}, with controlled
resource constrainedness (\cf\ Section~\ref{background}); plus the
Blocksworld as an intuitively differently structured domain.
%
In NoMystery, the action-set properties are as in our illustrative
example. In Rovers, the properties ask which rover or camera is used
for which observation. In TPP, they ask which road segments are used,
and which goods are bought at which markets. In Blocksworld, we
include two hands and the properties ask which hand is used for which
blocks.
%
We set the original goal facts as hard goals, so that the analysis
determines exclusion relations over conjunctions of action-set
properties.

We encoded resource consumption into the FDR state variables, enabling
the use of trap learning which turns out to be highly beneficial
here. We generated benchmarks of sizes around the feasibility
borderline, and we experimented with resource constrainedness
$x \in \{1.0, 1.25, 1.5, 2.0\}$. For reference, we ran \astar\
with \hlmcut\ as before, on all goal facts (original plus compiled
action-set properties). Current OSP planners cannot handle hard goals,
so we used our base planner with trap learning instead as a second
reference point.

%% \joerg{presumably, include a figure with one plot per domain,
%% fixing number of goals as in IJCAI long versions (main paper plot),
%% and with fixed constrainedness factor x. use same x for both global
%% and local explanations. x=2.0 is too high, Blocks and TPP
%% apparently typically all goals achievable easil for base
%% planner. x=1.0 shows off advantage of trap learning, but does not
%% challenge the reference points enough. for x=1.5 on the other hand
%% trap learning is way less important than for 1.0. Try x=1.25 and
%% see what it looks like.}
%
\begin{figure}[h!]
\vspace{-0.2cm}
\small
\centering

\input{charts.tex}
\vspace{-0.3cm}
\caption{\label{fig:asp-global} Coverage for global explanation on 
NoMystery (top left), Rovers (top right), TPP (bottom left),
Blocksworld (bottom right). Number of action-set properties on x-axis,
scaling from $1$ to $10$.\joerg{complete this plot. x-achsen
beschriftung oben und unten bitte komplett raus. Bitte die legend
unter diese plots, wie im IJCAI'19 long paper unter Figure 2.}}
\vspace{-0.2cm}
\end{figure}

For lack of space, we give only snapshots of our data.\footnote{We
intend to buy additional pages to include more complete data. For
AAAI'20 review, the data is in supplementary material at
{\scriptsize \url{https://www.dropbox.com/sh/boq29booqajj7ab/AACbKpiR6jdbeEzCldrvLfk4a?dl=0}}}
%
Figure~\ref{fig:asp-global} shows that computing global action-set
property explanations is moderately feasible compared to the reference
points. The data shown is for $x = 1.25$; for other values, what
varies is mainly the usefuless of trap learning, which peaks at $x =
1.0$ when resources are extremely scarce.
%
%% \joerg{this summary is extremely underwhelming, focusing exclusively 
%% on computational aspects, and saying ``not totally infeasible''. we
%% need something that highlights to the reviewer that/how this new form
%% of analysis is exciting and useful. examples of concrete analysis
%% results?}
%% %
%% In Blocksworld and TPP, our techniques are moderately competitive with
%% the reference points. In NoMystery, they are vastly inferior. In
%% Rovers, they vastly surpass \hlmcut, matching the coverage of the
%% trap-learning reference point. Overall, it seems fair to say that our
%% analysis here is not exceedingly infeasible compared to related
%% classical planning problems.
%
Figure~\ref{fig:asp-local} shows that, as before, the analysis becomes
much easier for local explanation as a function of question size.

\begin{figure}[h!]
\vspace{-0.2cm}
\small
\centering

\input{charts_local_exp.tex}
\vspace{-0.3cm}
\caption{\label{fig:asp-local} Local action-set property explanation 
results for SysS as a function of $|A|$. Coverage and average runtime
(left), average \#MUGS (right). NoMystery red, Rovers ???, TPP green,
Blocksworld ???. \joerg{integrate reference point coverage as
horizontal lines into the left plot}}
%
%\caption{$c = 1.25$ red: nomyters (5 goals, 5 props), green: TPP (7 goals, 9 props), left plot: search time and coverage, right plot: \#MUGS}
%
\vspace{-0.2cm}
\end{figure}



%%%% Action-Set Properties, END SUBMISSION VERSION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% PRE-FINAL AND SUPPLEMENTARY MATERIAL VERSION

\ifdefined\suppflagdefined

\subsection{Action-Set Properties}

\begin{figure*}[htb]
\centering\centering
%\input{data/action_set_properties/domain_selection.tex}
\includegraphics{data/action_set_properties/barchart/barchart.pdf}
\vspace{-0.6cm}
\caption{Coverage results on IPC benchmarks extended with action-set properties.}
\label{fig:barcharts}
\vspace{-0.2cm}
\end{figure*}

To evaluate the use of our framework with more complex plan
properties, beyond goal facts, we experimented with the compilation of
action-set properties as per Section~\ref{compilation}. We selected
four IPC domains for extension with action-set properties, namely
NoMystery, Rovers, and TPP as considered in resource-constrained
planning \cite{nakhost:etal:icaps-12}, where minimum resource
requirements are known as per available problem generators; plus the
Blocksworld as an intuitively rather differently structured domain. In
all four domains, we use discrete resource consumption encoded into
the STRIPS model, enabling the use of trap
learning \cite{steinmetz:hoffmann:ijcai-17} which turns out to be
highly beneficial here.

In Blocksworld, we include two gripper hands and the action-set
properties ask whether a given gripper is used to pick up a given
block, or to stack a given pair of blocks. In NoMystery, the
properties are as in our illustrative example
(Section~\ref{illustrative-example}). In Rovers, the properties ask
whether a given rover or camera is used for a given observation. In
TPP, they ask whether given road segments are used, and whether given
goods are bought at given markets. In all cases, we vary the number of
action-set properties between 1 and 10. We fix the original goal facts
as hard goals, and we set the available resources to $x \in \{1.0,1.5,
2.0\}$ times the minimum needed to allow for costlier plans satisfying
some of the properties.

We created benchmark tasks with size parameters around the borderline
of computational feasibility for our analyses, given our time/memory
limits. In Blocksworld, we used 5 -- 8 blocks; in NoMystery, our tasks
have 2 trucks, 6 locations, and 4 -- 7 packages; in Rovers, they have
2 rovers, 5 waypoints, and 4 -- 7 science objectives; in TPP, we use 5
markets, 1 depot, and 4 -- 7 goods. In all domains, we vary the number
of goal facts (and associated objects) between 4 and 7. We create 10
base instances for each size-parameter setting, which are then
modified for our experiments with different initial resource levels,
and action-set properties to be considered.
%
%% \begin{enumerate}
%% \item The resource constrained \textit{rovers} domain. Problems were generated with 2 rovers, 5 waypoints. Action properties are to use a specific rover for a sample or an observation, or to use a specific camera for an observation. 
%% \item The \textit{blocksworld} domain with 2 grippers, modified such that picking up or unstacking a block costs high or low energy depending upon which gripper is used. Problems were generated scaling from 3 to 10 blocks. Action properties are to use a specific gripper to pick up a specific block, or to use any gripper to stack a specific pair of blocks at any point in the plan.
%% \item The resource constrained \textit{TPP} domain. Problems were generated with 5 markets and 1 depot. Properties are to use or not use particular road segments, and preferred markets for goods.
%% \item The resource constrained \textit{nomystery} domain, described in the example. Problems were generated with 6 locations and 2 trucks.
%% \end{enumerate}

To have some comparison measure for performance, again we use
classical-planning reference points, based on \astar\ with \hlmcut,
and on search with trap learning, respectively. We now run these
reference points on tasks where all (original goal facts plus)
action-set properties are hard goals. These tasks may be solvable (in
which case \astar\ with \hlmcut\ tends to be better) or unsolvable (in
which case trap learning tends to be better). The configurations of
our own algorithm are SysS and SysW as before, now with vs.\ without
trap learning (and transfer).

Figure~\ref{fig:barcharts} shows the coverage data. To give an
overview, we show one row per domain, fixing the number of hard goals
at the feasibility borderline. Smaller numbers of goal facts tend to
be quite easy, larger ones mostly infeasible, with variance depending
on the domain and algorithm.
Appendix~\ref{data-action-set-properties} gives complete data for each
of the four domains.

In Blocksworld, the best of our techniques are moderately competitive
with the \hlmcut\ reference point (which starts to lose coverage when
one more block is added). They match the performance of the other
reference point for $x=1.0$, and surpass it for larger $x$ where trap
learning incurs a prohibitive overhead. NoMystery is the most
problematic domain in terms of performance, with all our techniques
lagging far behind the two reference points. In Rovers,
though, \astar\ with \hlmcut\ is much less effective than our
techniques, which match the full coverage of the trap-learning
reference point. TPP is similar to Blocksworld in that our techniques
are moderately competitive with the reference points. 
%\joerg{statement where coverage for these starts to go down} 
Trap learning is highly
beneficial in all cases except Blocksworld with $x>1.0$. Overall, it
seems fair to say that our action-set property dependency analysis is
not exceedingly infeasible compared to related classical planning
problems.


\fi

%%%% END PRE-FINAL AND SUPPLEMENTARY MATERIAL VERSION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

