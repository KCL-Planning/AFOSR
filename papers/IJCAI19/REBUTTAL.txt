




======================================================================================================
======================================================================================================
Review #210401 

Thanks for your thoughtful comments. 

> The idea of using dependencies to provide contrastive explanations
> seems significant to me, and is a good fit with planning search
> spaces. I also appreciate the fact that experiments have been
> conducted to check computational feasibility on a all IPC
> benchamarks. Of course, the usefulness of the work would have to be
> tested by presenting explanations to users and that's lacking for
> now.  It is a bit disappointing that the approach doesn't seem to
> scale to LTL properties, but maybe the trick is not to use
> compilation and just to generate a plan satisfying the LTL formulas
> as part of the test in the algorithm (but then maybe you wouldn't
> have the conflicts implementation for free?)

LTL remains a challenge, yes. Our most recent findings suggest that
there is room for improvement in compilation design. But yes, not
using compilation may be the way to go.

As a side note here: we did not quite get the conflicts
analysis/nogood learning methods "for free". We have added only a
brief description for space reasons, but the extensions, while not
exceedingly deep, are not trivial. We plan to buy additional space for
the final version if accepted, mainly to add the empirical results
from the supplementary material. This will also allow to add a more
detailed description of the nogood learning extensions as well as more
discussion of related work (see next).


> The weakest point of the paper however is the positioning of the
> work with respect to the broader AI literature. How does all this
> relate to areas such as model-based diagnosis, explanations,
> ATMS. For instance, with the exception of the "dependencies" there
> are pretty strong connections between the framework and techniques
> used here and those used in model-based diagnosis to generate all
> minimal diagnoses in circuits or discrete-event systems, see for
> instance the seminal work by Reiter, right up to more recent work by
> Grastien for discrete-event system. In fact, except for the original
> idea of using plan dependencies, the rest of the machinery used,
> including the weakening/strengthening algorithm, the planning
> approach to do the checks, the compilations and so on aren't so
> original. But the paper brings them together in a nice way.

TODO: Draft reply, Daniele please check.

Indeed the weakening/strengthening algorithms are similar to various
methods in the literature, solving problems requiring to find the
borderline between solvable vs. unsolvable (in some sense) nodes in a
preference lattice. This pertains to ATMS, and in particular to works
on diagnosis where the lattice of goal conjunctions can be viewed as a
lattice of hypotheses. We agree with you that it was an ommission on
our part to not mention these connections. We will fix that ommission
in the final version if accepted. As you point out yourself though,
our main contribution is not in these algorithms per se (and we did
not mean to claim they were), but in the overall framework, its
instantiation, and empirical evaluation.

That said, regarding the planning approach we use to do the checks in
SysW and SysS, and ŕegarding compilations, we have included the
relevant citations -- the planning algorithms we use, and a
representative selection of papers on compilation methods.

NOTE:

I think we should add a related work section like I oririginally
thought; this is the best way I can think of to discuss such more
distant relations, that would be distracting in an introduction (but
we should not mention a new related work section in the rebuttal, or
else the reviewers may say "well this section should have been in the
submission already").

NOTE:

Here follow detailed notes on each of the 4 papers.

> Johan de Kleer: Extending the ATMS. Artif. Intell. 28(2): 163-196
> (1986):
> https://www.sciencedirect.com/science/article/abs/pii/0004370286900810?via%3Dihub

ATMS (previous paper introduces them, AIJ 1986) associate a "datum"
determined by a "problem solver" with the set of environments that
entail that datum. An environment is a set of assumptions. The set of
environments shuld be complete (represent all environments that entail
the datum) as well as minimal. Hence one gets a lattice of
environments and needs to identify the borderline between entailing
and non-entailing ones, which is equivalent to a borderline between
solvable and unsolvable formulas. This seems the only connection to
our work.

> Raymond Reiter: A Theory of Diagnosis from First
> Principles. Artif. Intell. 32(1): 57-95 (1987)
> https://www.sciencedirect.com/science/article/pii/0004370287900622

From description of static diagnosis in papers below: set of
components c; if c is non-faulty it implies a formula phi; a diagnosis
candidate is a set of c whose faultiness leads to consistency of the
set of phi; task is to find all minimal diagnosis candidates; this is
done in an iterative strengthening fashion, starting with the empty
diagnosis and, in any leaf node, adding one more faulty component in
case the node is not a diagnosis candidate ie still contains a
conflict; children need only be generated for faulty components
responsible for the conflict (something not doable/relevant in our
context as it relies on the simple representation).


> Alban Grastien, Patrik Haslum, Sylvie Thiébaux: Conflict-Based
> Diagnosis of Discrete Event Systems: Theory and Practice. KR 2012
> https://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4558

Very general framework for diagnosis, where there is a system model M
desribing transition behaviour of a system (event sequences); a subset
o of observable events, were the input to diagnosis is the subsequence
of observed events; and a hypothesis space H with a function
hypo(sigma) that maps each event sequence to exactly one
hypothesis. In our setting, M is the planning task, events being
actions; o is empty because the MUGS analysis receives no observations
on which action sequences are possible; and H is the set of all goal
conjunctions, with hypo(sigma) being the goal conjunction true at the
end of sigma.

With this correspondence, the diagnosis (Def 2 in the paper) is the
set of all goal conjunctions for which there exists an action sequence
achieving that conjunction -- ie, the set of all solvable goal
conjunctions. The preference relation is superset, and the minimal
diagnosis (Def 3 in the paper) is the set of maximal solvable goal
conjunctions (from which the MUGS can be derived easily).

The preferred-first algorithm, Algorithm 1, given in the paper starts
from the most preferred hypothesis (here: the conjunction of all
goals). It pops a node from the queue, tests whether it is part of the
diagnosis (here: whether it is solvable); if so, the node is added to
the result res, if not its direct descendants (here: the conjunctions
reduced by removing a single goal) are inserted into the queue. So
this is exactly like our systematic weakening except that res collects
the solvable nodes, not the unsolvable ones with solvable children
only.

In this sense, our systematic weakening algorithm is an instance of
their framework. They use SAT solvers though for the test in each
node.

The most interesting aspects pertain to conflict analysis:

1. Algorithm 1 in the paper contains a pruning mechanism that
essentially asks whether a node can lead to any solvable descendants
that are not already reflected in res or in the nodes still open; if
not, the node is pruned. Essentially, this is saying that one may be
able to prune nodes based on the results generated so far, with
additional solver tests whether the node can go beyond these
results. We do not use this yet, and it is not clear whether it will
be effective in our setting; but it is a possible direction for future
work we could look into.

2. The tests in the paper re all done independently, i.e. they do not
transfer information. In contrast, our tests do through nogood
transfer. This is a possible improvement to their work.

3. Algorithm 1 in the paper is extended with "conflicts", ie
additional hypotheses that the test solver determined to fail. In our
setting, this means that the planner called determins not only th
given goal conjunction to be unsolvable, but others as well. This
corresponds to nogoods valid in the initial state. We coukd in
principle derive such nogoods, by continuing the nogood learning after
the search tree is already completed and we know the task/the current
goal conjunction to be unsolvable. This would incur overhead for the
additional nogood learning (which can be quite substantial, see our
AIJ paper), but may help to reduce the meta-search. So, another
possible direction for future work we could look into.

> Alban Grastien, Patrik Haslum, Sylvie Thiébaux. Exhaustive diagnosis
> of discrete event systems through exploration of the hypothesis
> space. DX-11 http://www.grastien.net/ban/articles/ght-dx11.pdf

Diagnosis framework similar to the one above. Top-down algorithm
(called pfs here) also similar, but less elaborated. In addition,
bottom-up style algorithm (called pls) starting with empty set of
diagnosis candidates, and iteratively adding a new candidate not
dominated by the ones already collected. Encodings into planning and
SAT.


> Before section 2.2: "we cannot have p without forgoing either of q1
> or q2 or q3". Do you mean without forgoing at least one of q1, q2,
> or q3?

Yes that is what we mean. We will reformulate.

> Definition 4: I am having difficulties understanding the
> relationship between =>_suff and {\cal M}_{\Pi}(p) \subseteq {\cal
> M}_{\Pi}(q) in definition 2.

{\cal M}_{\Pi}(p) \subseteq {\cal M}_{\Pi}(q) characterizes
plan-property entailment. =>_suff denotes an easy-to-test sufficient
criterion for such entailment.

> Under Definition 7: I could not understand why "Given the
> restriction to D^{GE}, the equivalence classes in the PDO-GE are
> singletons". Maybe I am overloaded with the notations, or maybe the
> sentence means something different than what I think it means.

In a retricted PDO, we disconsider all entailments outside the given
set D. For D^{GE} we thus consider only entailments of the form "A ==>
not B". So no two formulas in P^{GE} can entail each other.



======================================================================================================
======================================================================================================
Review #256505

Thanks for your thoughtful comments. 

> As far as I understood, the plan explanation approach here described
> depends on the quality of the knowledge base represented by the set
> of plans $\Pi$. This can actually represent a limitation in applying
> this approach to the general case.  How the approach can be used
> inside a decision support system? Does the calculation of $\Pi$
> require a significant time?

As our experiments show, our analysis often is "feasible"
computationally, in the sense of not being more infeasible than the
most closely related classical planning problems.

> Maybe, if significant, the authors can add the computational times
> in the case of the four domains of the empirical evaluation

The empirical results for these four domains are given in the
supplementary material. We plan to buy additional space for the final
version if accepted, to add these results to the paper.

> There is one aspect I would like the authors to comment.  As other
> previous works, this approach is based on computing an explanation a
> posteriori.  Have the authors consider the possibility of creating
> this explanation while generating a plan?  This probably might
> require to change the way plans are generated. And maybe considering
> to have less optimal but explainable by construction plans could be
> acceptable.

TODO: Daniele here is a draft but I'm not sure about it; not sure if I
understand the question well.

Note that a PDO can actually be computed offline, prior to planning,
in principle. The limiting factor in that setting is the set P of plan
properties considered, that must then be fixed a priori. In some
applications at least, it will probably be necessary to identify new
relevant plan properties online as part of the user interaction,
e.g. in an iterative planning process as briefly mentioned in the
introduction. In such a context, new entailment relations must be
computed online. Your question how to combine this with the planning
process is then very relevant. We don't have concrete ideas on this
yet, but it could be an interesting question for future research.

> Minor: in the example I found a bit confusing that the user's
> question refers to a concept, the traffic, that it is not part of
> the model.

TODO: Daniele, do you wanna comment on this?


======================================================================================================
======================================================================================================
Review #261148

Thanks for your thoughtful comments. The open issues you point out are
on the spot in our view. We agree that these things should be done
eventually -- but we respectfully point out that they are beyond scope
of this first paper initiating the work line. As you say yourself, we
managed to fit both the abstract problem description and a specific
instantiation into the paper. With the empirical evaluation of
computational aspects, the paper is full to the brim; indeed the part
of our experiments pertaining to the more powerful action-set
properties had to be moved to the supplementary material (we plan to
buy additional space for the final version, if accepted, to include
these results into the paper).

> My first (and probably the most difficult to tackle) comment is
> that, if this paper is about producing useful explanations for
> users, the experimental work is incomplete at the moment as it does
> not present any user studies. This is the only rigorous way to
> assess whether the method achieves its objectives regarding
> explainability. I am aware this is not trivial, but such studies are
> performed in many fields of CS and can be done by the AI planning
> community too.

We agree, and we mention this as future work in the conclusion. As a
proof of concept that our answers *may* be suitable for user
inspection in principle, we include in our evaluation the #MUGS data,
which shows that, often, even the full PDO (the full plan space
explanation in our framework) can be compactly described.

> Besides, I am not entirely sure that the explanations provided
> within this setting would be that useful for the user. In my view,
> an explanation should offer both a rationale behind a choice and the
> reasoning process that has led to that choice. In the method
> presented by the authors, this reasoning process remains opaque to
> the users, as far as I understand.

In the present paper, yes, we provide merely the plan-property
dependencies themselves. We agree that, in the long term, also the
reasons behind these dependencies should be explainable, answering
"why does this dependency hold true?" questions. In the conclusion, we
mention two concrete ideas to answer such questions. Embarking on
these ideas is among our next steps.

> Also, in this framework, it seems possible to generate complex
> explanations. How do the authors envisage to moderate this
> complexity?

Our #MUGS data shows that, at least in the analysis of goal
dependencies, the full plan-space explanation -- the complete PDO --
can often be communicated compactly. In general, of course, this is
not the case. But for specific questions "why A not B?" the answer is
just a fragment of the PDO (the properties C entailed by B). Beyond
this, in the long term it seems promising to investigate relevance
filters, based e.g. on prior experience with the same user, or on a
preceding interaction context.

> Another problematic part is that the properties are considered an
> input. It will be non-trivial to identify them in advance in such a
> way to predict possible user questions. How do the authors count to
> do that? Are they thinking to do it collaboration with the users?

Automatically finding/mining the plan properties indeed is one of the
most interesting avenues ahead (see our footnote in the
introduction). Possible ideas towards this are, yes,
collaborating/interacting with the user, e.g. in an example-critiquing
fashion; or iteratively broadening a given set P by generalizing from
differences between example plans that do vs. do not satisfy some p
\in P.

> Finally, the framework is instantiated only for one particular
> problem in planning, oversubscription planning. It would be
> interesting to consider another example and show that the same
> concepts work in a different context. I realize this might be
> difficult given the space limitations.

Indeed this is not possible given space. Note that the paper is
already full to the brim and we had to defer part of our empirical
results to the supplementary material.

> Overall, this paper is very interesting, but I believe it is somewhat
> in a preliminary stage, in particular, the experimental part, which
> does not help in assessing the technique in the context in which it is
> situated by the authors themselves, i.e. explainable AI.

In our view, given the complex decision problems involved in our
analysis, a computational evaluation is absolutely
necessary. Furthermore it seems fair to say that, if we had not
performed and included such an evaluation, its absence would have been
reason to reject for most review panels.

> As a minor point, in the introduction there is a misalignment
> between the question “Why do A rather than B?” and “Why does the
> current plan π satisfy p rather than q?”. While if one keeps reading
> the paper, the mismatch gets resolved, I believe it would be
> beneficial to clarify since the beginning that the two questions can
> be mapped into each other within the framework. Finally, related
> work should be discussed more in depth.

Thanks. We will try to improve for a final version of accepted.



======================================================================================================
======================================================================================================
Review #261149

Thanks for your thoughtful comments. 

Regarding our formal framework and MUGS:

In our humble opinion, the generic framework is useful to outline the
approach and problem beyond the special case of goal
dependencies. This also gives much more room for other researchers to
build upon our work/to explore new aspects of the problem addressed,
than a much more narrow paper focussing entirely on goal dependencies.

MUGS lend themselves to addressing powerful plan-property languages
via compilation. We exemplify this with the action-set properties
addressed in Section 4, and briefly discussed in the experiments
section with detailed empirical data given in the supplementary
material. 

Furthermore, LTL can be dealt with by plugging in known compilation
techniques. Indeed we have already implemented this prototypically. We
briefly mention this at the end of Section 4, but it may be too
under-emphasized in the current write-up. We will expand this
discussion if accepted.

> In particular, in the context of the example in Sec.5, it is not
> clear to me why do you not just add the user's requested property to
> the properties already achieved by the plan and output that it is
> impossible to achieve the user's request, if no plan achieving all
> properties can be found? To me this seems more efficient than
> computing all possible MUGS's and then seeing if the user's
> requested property added to the current goal is a MUGS already
> encountered.

The answer given by the MUGS is much more specific. It specifies the
conflicting property (here: transporting all packages with a single
truck). The solvability test you suggest would only say that we cannot
enforce property 5 together with the properties the plan already
has. A goal subset minimization step is necessary to arrive at the
more specific answer. One could, of course, do that goal subset
minimization step on the fly instead, as part of the interaction with
a user. This comes down to computing a subset of the PDO on the
fly. This certainly is one development line for future work.

> "a plan property is a partial function p : T × P → {true, false}":
>     would it be simpler to represent it as a relation?

TODO: This is a really stupid comment. The answer is, of course,
"no". Daniele, should we simply ignore?

> Should "D^{GE} := {( a\in A a,\neg b\in B b) | A \cap B = \emptyset}"
>     be "D^{GE} := {( a\in A a,\neg b\in B b) | A \cap B = \emptyset
>     \wedge (A \cup \B) \subseteq G}" ?

Yes indeed, thanks.

> "We say that p Π-entails q, written..": could you clarify whether
>     "p" can be a general propositional formula? If it can, then you
>     seem to overload the right-arrow between your meta-logic and
>     object-logic, e.g. in "φ ⇒ ψ" vs. "Π |= φ ⇒ ψ" on page 2.

p is a function on plans, that returns a Boolean. That function can in
particular evaluate a formula, so in this sense, as we point out in
the paper below Definition 2, the answer to your question is yes. It
is not clear to us though what you find confusing here. Like we say,
Pi-entailment is essentially like entailment within a knowledge base
(given in the form of Pi). If you can elaborate your concern a bit
more, we will try to address it in our revision.

> What does "\bigwedge_{a\in A} a" mean if "A = \emptyset"

The empty conjunction in our paper means True. We thought this to be
quite common, but actually yes it should be made explicit, so thanks
for pointing it out.

> Proposition 1 seems false to me: suppose A and B are non-empty
>     sets. Suppose that there are no plans that satisfy any "a \in
>     A". Then we have "Π |= /\_{a \in A} ⇒ P", for any P. However, "A
>     \cup B" is not a MUGS, since "A \subset B", but there are not
>     plans achieving all properties in A.

In the situation you describe, we have "A ==> not B", but that
implication is not part of the dominant cPDO as per Definition 4. This
is because each a in A on its own already is unsolvable. In detail: We
use the sufficient criterion ==>_suff for entailment as described at
the end of Section 3.2, saying that larger conjunctions entail smaller
ones and smaller negated conjunctions entail larger ones. Given this,
the entailment "{a} ==> not B" for each a in A subsumes (see Def 4)
the entailment "A ==> not B". Similarly, the entailment "{a} ==> not
{}" subsumes the entailment "{a} ==> not B" for each a in A. So the
dominant PDO-GE contains exactly the entailments "{a} ==> not {}" for
a in A. These are in 1-to-1 correspondence with the MUGS {a} for a in
A.




